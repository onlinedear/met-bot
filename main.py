# filename: main.py
"""
åŒ»ç–—æƒ…æŠ¥è‡ªåŠ¨æ”¶é›†ä¸æ¨é€æœºå™¨äºº (v3.0 å¤šæ¨¡å‹ç‰ˆ)

åŠŸèƒ½: ä» RSS æºè·å–åŒ»å­¦æ–‡çŒ®ï¼Œä½¿ç”¨ AI æ€»ç»“ï¼Œæ¨é€åˆ° Telegram
æ”¯æŒ: Gemini, DeepSeek, è±†åŒ…(Doubao), é€šä¹‰åƒé—®(Qwen)
"""

# ============================================================
# å¯¼å…¥æ¨¡å—
# ============================================================

# æ ‡å‡†åº“
import json
import logging
import os
import time
from datetime import datetime
from typing import Optional

# ç¬¬ä¸‰æ–¹åº“
import feedparser
import google.generativeai as genai
import requests
from openai import OpenAI

# ============================================================
# é…ç½®åŒºåŸŸ
# ============================================================

# --- Telegram é…ç½® ---
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID", "")

# --- AI æä¾›å•†é…ç½® ---
# å¯é€‰å€¼: gemini, deepseek, doubao, qwen (é»˜è®¤ gemini)
AI_PROVIDER = os.environ.get("AI_PROVIDER", "gemini").lower()

# å„ AI æä¾›å•†çš„ API Key
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")
DEEPSEEK_API_KEY = os.environ.get("DEEPSEEK_API_KEY", "")
DOUBAO_API_KEY = os.environ.get("DOUBAO_API_KEY", "")
QWEN_API_KEY = os.environ.get("QWEN_API_KEY", "")

# è‡ªå®šä¹‰æ¨¡å‹åç§° (å¯é€‰ï¼Œç”¨äºæŒ‡å®šå…·ä½“æ¨¡å‹æˆ–è±†åŒ…çš„æ¥å…¥ç‚¹ ID)
AI_MODEL_NAME = os.environ.get("AI_MODEL_NAME", "")

# --- RSS æºåˆ—è¡¨ ---
RSS_SOURCES = [
    {
        "name": "PubMed - Pediatric SLE",
        # æœç´¢å…³é”®è¯: Systemic Lupus Erythematosus AND Child
        "url": "https://pubmed.ncbi.nlm.nih.gov/rss/search/14_xQ7JEOWXDuopaPahtu8vYOV9ttMUxoq8IeKOLBpA7Zak9UG/?limit=15&utm_campaign=pubmed-2&fc=20260103215413",
    },
    {
        "name": "Top Journals (NEJM/Lancet/Nature/ARD)",
        # é¡¶çº§æœŸåˆŠçº¢æ–‘ç‹¼ç–®ç ”ç©¶
        "url": "https://pubmed.ncbi.nlm.nih.gov/rss/search/1houoX_LGC3Y5rpUnbir5VljX_fEj1HoolaYuUt4RMxsPBbkIL/?limit=15&utm_campaign=pubmed-2&fc=20260106101820",
    },
    {
        "name": "ClinicalTrials - Pediatric Lupus",
        # æœç´¢å…³é”®è¯: SLE (Condition) + Child (Term)
        "url": "https://clinicaltrials.gov/api/rss?cond=Systemic+Lupus+Erythematosus&term=Child",
    },
]

# --- å†å²è®°å½•é…ç½® ---
HISTORY_FILE = "history.json"
MAX_HISTORY_SIZE = 1000  # æœ€å¤§å†å²è®°å½•æ•°é‡ï¼Œé˜²æ­¢æ–‡ä»¶æ— é™å¢å¤§

# --- æ—¥å¿—é…ç½® ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)


# ============================================================
# å†å²è®°å½•ç®¡ç†
# ============================================================

def load_history() -> set:
    """
    åŠ è½½å†å²è®°å½•æ–‡ä»¶ã€‚

    Returns:
        å·²å¤„ç†è¿‡çš„æ–‡ç«  ID é›†åˆ
    """
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                logger.info(f"å·²åŠ è½½ {len(data)} æ¡å†å²è®°å½•")
                return set(data)
        except (json.JSONDecodeError, IOError) as e:
            logger.warning(f"è¯»å–å†å²è®°å½•å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨ç©ºè®°å½•")
            return set()
    else:
        logger.info("å†å²è®°å½•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°è®°å½•")
        return set()


def save_history(history: set) -> None:
    """
    ä¿å­˜å†å²è®°å½•åˆ°æ–‡ä»¶ï¼Œè‡ªåŠ¨æˆªæ–­è‡³æœ€å¤§æ•°é‡ã€‚

    Args:
        history: æ–‡ç«  ID é›†åˆ
    """
    history_list = list(history)
    if len(history_list) > MAX_HISTORY_SIZE:
        history_list = history_list[-MAX_HISTORY_SIZE:]

    try:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(history_list, f, ensure_ascii=False, indent=2)
        logger.info(f"å·²ä¿å­˜ {len(history_list)} æ¡å†å²è®°å½•")
    except IOError as e:
        logger.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")


# ============================================================
# RSS è§£æ
# ============================================================

def fetch_rss_articles(sources: list) -> list:
    """
    ä» RSS æºè·å–æ–‡ç« åˆ—è¡¨ï¼ŒåŒ…å«åçˆ¬è™«ç­–ç•¥ã€‚

    Args:
        sources: RSS æºé…ç½®åˆ—è¡¨

    Returns:
        æ–‡ç« åˆ—è¡¨ï¼Œæ¯ç¯‡åŒ…å« id, title, link, summary, source, published
    """
    articles = []
    session = requests.Session()

    for source in sources:
        source_name = source.get("name", "Unknown")
        url = source.get("url", "")

        if not url:
            continue

        logger.info(f"æ­£åœ¨è·å–: {source_name}")

        # é’ˆå¯¹ä¸åŒæ¥æºå®šåˆ¶ Headers
        if "pubmed" in url.lower():
            headers = {
                "User-Agent": "MedicalIntelligenceBot/1.0 (Research Purpose)",
                "Referer": "https://pubmed.ncbi.nlm.nih.gov/",
                "Accept": "*/*",
            }
        else:
            # ClinicalTrials ç­‰å…¶ä»–ç½‘ç«™æ¨¡æ‹Ÿæµè§ˆå™¨
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            }

        try:
            # å»¶æ—¶é¿å…å°ç¦
            time.sleep(2)
            response = session.get(url, headers=headers, timeout=30)
            response.raise_for_status()

            feed = feedparser.parse(response.content)

            current_count = 0
            for entry in feed.entries:
                article_id = entry.get("id") or entry.get("link") or entry.get("title", "")
                if not article_id:
                    continue

                articles.append({
                    "id": article_id,
                    "title": entry.get("title", "æ— æ ‡é¢˜"),
                    "link": entry.get("link", ""),
                    "summary": entry.get("summary", entry.get("description", "æ— æ‘˜è¦")),
                    "source": source_name,
                    "published": entry.get("published", ""),
                })
                current_count += 1

            logger.info(f"ä» '{source_name}' è·å–äº† {current_count} ç¯‡æ–‡ç« ")

        except Exception as e:
            logger.error(f"è·å– '{source_name}' å¤±è´¥: {e}")

    session.close()
    return articles


def filter_new_articles(articles: list, history: set) -> list:
    """
    è¿‡æ»¤å‡ºæ–°æ–‡ç« ï¼ˆä¸åœ¨å†å²è®°å½•ä¸­çš„ï¼‰ã€‚

    Args:
        articles: å…¨éƒ¨æ–‡ç« åˆ—è¡¨
        history: å†å²è®°å½• ID é›†åˆ

    Returns:
        æ–°æ–‡ç« åˆ—è¡¨
    """
    new_articles = [a for a in articles if a.get("id") and a.get("id") not in history]
    logger.info(f"å‘ç° {len(new_articles)} ç¯‡æ–°æ–‡ç« ")
    return new_articles


# ============================================================
# AI æ€»ç»“ (å¤šæ¨¡å‹æ”¯æŒ)
# ============================================================

def build_prompt(articles: list) -> str:
    """
    æ„å»ºå‘é€ç»™ AI çš„ Promptã€‚

    Args:
        articles: æ–‡ç« åˆ—è¡¨

    Returns:
        æ ¼å¼åŒ–çš„ Prompt å­—ç¬¦ä¸²
    """
    articles_text = ""
    for i, article in enumerate(articles, 1):
        summary_truncated = article["summary"][:500]
        articles_text += (
            f"\n--- æ–‡ç«  {i} ---\n"
            f"æ ‡é¢˜: {article['title']}\n"
            f"æ‘˜è¦: {summary_truncated}...\n"
            f"é“¾æ¥: {article['link']}\n"
        )

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªé£æ¹¿å…ç–«ç§‘ä¸“å®¶ï¼Œè¯·å°†ä»¥ä¸‹å…³äº"å„¿ç«¥çº¢æ–‘ç‹¼ç–®"çš„æœ€æ–°æ–‡çŒ®æ•´ç†æˆä¸­æ–‡æ—¥æŠ¥ã€‚

æ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d')}

è¦æ±‚ï¼š
1. åˆ†ä¸ºã€é‡ç£…ã€‘ã€ã€ä¸´åºŠã€‘ã€ã€åŸºç¡€ã€‘ä¸‰ç±»ã€‚
2. æ¯ä¸ªæ¡ç›®åŒ…å«ï¼šä¸­æ–‡æ ‡é¢˜ã€ä¸€å¥è¯é€šä¿—è§£è¯»ã€åŸæ–‡é“¾æ¥ã€‚
3. ä¿æŒä¸“ä¸šä¸”æ˜“è¯»ã€‚
4. é‡è¦ï¼šè¯·ä¸è¦åœ¨è¾“å‡ºä¸­ä½¿ç”¨ä¸é—­åˆçš„ Markdown ç¬¦å·ï¼ˆå¦‚å•ä¸ª * æˆ– _ï¼‰ï¼Œå°½é‡é¿å…ä½¿ç”¨å¤æ‚çš„æ ¼å¼ï¼Œä½¿ç”¨çº¯æ–‡æœ¬æˆ–ç®€å•çš„ emoji å³å¯ã€‚

å¾…å¤„ç†æ–‡çŒ®ï¼š
{articles_text}
"""
    return prompt


def generate_with_gemini(prompt: str) -> Optional[str]:
    """
    ä½¿ç”¨ Google Gemini ç”Ÿæˆæ€»ç»“ã€‚

    Args:
        prompt: æç¤ºè¯

    Returns:
        ç”Ÿæˆçš„æ–‡æœ¬ï¼Œå¤±è´¥è¿”å› None
    """
    if not GEMINI_API_KEY:
        logger.error("æœªé…ç½® GEMINI_API_KEY")
        return None

    try:
        genai.configure(api_key=GEMINI_API_KEY)

        logger.info("æ­£åœ¨è‡ªåŠ¨é€‰æ‹©æœ€ä½³ Gemini æ¨¡å‹...")
        available_models = []
        try:
            for m in genai.list_models():
                if "generateContent" in m.supported_generation_methods:
                    available_models.append(m.name)
        except Exception as e:
            logger.warning(f"æ— æ³•åˆ—å‡ºæ¨¡å‹ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤å€¼: {e}")

        # ç¡®å®šæ¨¡å‹åç§°
        model_name = AI_MODEL_NAME if AI_MODEL_NAME else "models/gemini-pro"

        # ä¼˜å…ˆé€‰æ‹©ç­–ç•¥: Flash > Pro > å…¶ä»–
        if available_models and not AI_MODEL_NAME:
            flash_models = [m for m in available_models if "flash" in m]
            pro_models = [m for m in available_models if "pro" in m]

            if flash_models:
                model_name = flash_models[0]
            elif pro_models:
                model_name = pro_models[0]

        logger.info(f"å·²é€‰æ‹© Gemini æ¨¡å‹: {model_name}")
        model = genai.GenerativeModel(model_name)

        response = model.generate_content(prompt)
        if response and response.text:
            logger.info("Gemini æ€»ç»“ç”ŸæˆæˆåŠŸ")
            return response.text

    except Exception as e:
        logger.error(f"Gemini æ€»ç»“å¤±è´¥: {e}")

    return None


def generate_with_openai_compatible(prompt: str, provider: str) -> Optional[str]:
    """
    ä½¿ç”¨ OpenAI å…¼å®¹æ¨¡å¼è°ƒç”¨ DeepSeek / è±†åŒ… / é€šä¹‰åƒé—®ã€‚

    Args:
        prompt: æç¤ºè¯
        provider: æä¾›å•†åç§° (deepseek, doubao, qwen)

    Returns:
        ç”Ÿæˆçš„æ–‡æœ¬ï¼Œå¤±è´¥è¿”å› None
    """
    # æä¾›å•†é…ç½®è¡¨
    config = {
        "deepseek": {
            "base_url": "https://api.deepseek.com",
            "api_key": DEEPSEEK_API_KEY,
            "default_model": "deepseek-chat",
        },
        "doubao": {
            "base_url": "https://ark.cn-beijing.volces.com/api/v3",
            "api_key": DOUBAO_API_KEY,
            "default_model": "",  # è±†åŒ…å¿…é¡»é€šè¿‡ AI_MODEL_NAME æŒ‡å®šæ¥å…¥ç‚¹ ID
        },
        "qwen": {
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "api_key": QWEN_API_KEY,
            "default_model": "qwen-plus",
        },
    }

    if provider not in config:
        logger.error(f"æœªçŸ¥çš„ AI æä¾›å•†: {provider}")
        return None

    cfg = config[provider]
    api_key = cfg["api_key"]
    base_url = cfg["base_url"]
    model_name = AI_MODEL_NAME if AI_MODEL_NAME else cfg["default_model"]

    if not api_key:
        logger.error(f"æœªé…ç½® {provider.upper()}_API_KEY")
        return None

    if not model_name:
        logger.error(f"ä½¿ç”¨ {provider} æ—¶å¿…é¡»é€šè¿‡ AI_MODEL_NAME ç¯å¢ƒå˜é‡æŒ‡å®šæ¨¡å‹/æ¥å…¥ç‚¹ ID")
        return None

    logger.info(f"æ­£åœ¨è°ƒç”¨ {provider.upper()} API (æ¨¡å‹: {model_name})...")

    try:
        client = OpenAI(api_key=api_key, base_url=base_url)

        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é£æ¹¿å…ç–«ç§‘åŒ»å­¦æ–‡çŒ®åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt},
            ],
            temperature=0.7,
            max_tokens=4096,
        )

        if response and response.choices and response.choices[0].message:
            result = response.choices[0].message.content
            logger.info(f"{provider.upper()} æ€»ç»“ç”ŸæˆæˆåŠŸ")
            return result

    except Exception as e:
        logger.error(f"{provider.upper()} æ€»ç»“å¤±è´¥: {e}")

    return None


def generate_ai_summary(articles: list) -> Optional[str]:
    """
    æ ¹æ® AI_PROVIDER é…ç½®è°ƒç”¨å¯¹åº”çš„ AI æœåŠ¡ç”Ÿæˆæ€»ç»“ã€‚

    æ”¯æŒçš„æä¾›å•†:
        - gemini: Google Gemini (é»˜è®¤)
        - deepseek: DeepSeek
        - doubao: å­—èŠ‚è·³åŠ¨è±†åŒ…
        - qwen: é˜¿é‡Œé€šä¹‰åƒé—®

    Args:
        articles: æ–‡ç« åˆ—è¡¨

    Returns:
        AI ç”Ÿæˆçš„æ€»ç»“æ–‡æœ¬ï¼Œå¤±è´¥è¿”å› None
    """
    if not articles:
        logger.info("æ²¡æœ‰æ–°æ–‡ç« ï¼Œæ— éœ€ AI æ€»ç»“")
        return None

    prompt = build_prompt(articles)
    logger.info(f"å½“å‰ AI æä¾›å•†: {AI_PROVIDER.upper()}")

    if AI_PROVIDER == "gemini":
        return generate_with_gemini(prompt)
    elif AI_PROVIDER in ["deepseek", "doubao", "qwen"]:
        return generate_with_openai_compatible(prompt, AI_PROVIDER)
    else:
        logger.error(f"ä¸æ”¯æŒçš„ AI æä¾›å•†: {AI_PROVIDER}ï¼Œæ”¯æŒçš„å€¼: gemini, deepseek, doubao, qwen")
        return None


# ============================================================
# Telegram æ¨é€
# ============================================================

def escape_markdown(text: str) -> str:
    """
    è½¬ä¹‰ Telegram Markdown ä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œé˜²æ­¢è§£æé”™è¯¯ã€‚

    Args:
        text: åŸå§‹æ–‡æœ¬

    Returns:
        è½¬ä¹‰åçš„æ–‡æœ¬
    """
    def fix_unpaired(text: str, char: str) -> str:
        """ä¿®å¤ä¸æˆå¯¹çš„ç‰¹æ®Šå­—ç¬¦"""
        count = text.count(char)
        if count % 2 != 0:
            text = text.replace(char, "\\" + char)
        return text

    text = fix_unpaired(text, "*")
    text = fix_unpaired(text, "_")
    text = fix_unpaired(text, "`")

    # è½¬ä¹‰ [ ä½†ä¿ç•™æœ‰æ•ˆçš„é“¾æ¥æ ¼å¼ [text](url)
    result = []
    i = 0
    while i < len(text):
        if text[i] == "[":
            close_bracket = text.find("]", i)
            if close_bracket != -1 and close_bracket + 1 < len(text) and text[close_bracket + 1] == "(":
                result.append(text[i])
            else:
                result.append("\\[")
        else:
            result.append(text[i])
        i += 1

    return "".join(result)


def send_telegram_message(text: str) -> bool:
    """
    å‘é€æ¶ˆæ¯åˆ° Telegramï¼Œå¤±è´¥æ—¶è‡ªåŠ¨é™çº§ä¸ºçº¯æ–‡æœ¬ã€‚

    Args:
        text: æ¶ˆæ¯æ–‡æœ¬

    Returns:
        æ˜¯å¦å…¨éƒ¨å‘é€æˆåŠŸ
    """
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        logger.error("æœªé…ç½® TELEGRAM_BOT_TOKEN æˆ– TELEGRAM_CHAT_ID")
        return False

    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"

    # åˆ‡åˆ†é•¿æ¶ˆæ¯ (Telegram å•æ¡æ¶ˆæ¯é™åˆ¶ 4096 å­—ç¬¦)
    max_length = 4000
    messages = []
    remaining = text

    while len(remaining) > 0:
        if len(remaining) > max_length:
            split_idx = remaining.rfind("\n", 0, max_length)
            if split_idx == -1:
                split_idx = max_length
            messages.append(remaining[:split_idx])
            remaining = remaining[split_idx:].lstrip("\n")
        else:
            messages.append(remaining)
            remaining = ""

    all_success = True

    for i, msg in enumerate(messages, 1):
        # æ–¹æ¡ˆ A: å°è¯• Markdown å‘é€
        escaped_msg = escape_markdown(msg)
        payload = {
            "chat_id": TELEGRAM_CHAT_ID,
            "text": escaped_msg,
            "parse_mode": "Markdown",
            "disable_web_page_preview": True,
        }

        try:
            resp = requests.post(url, json=payload, timeout=30)
            if resp.status_code == 200:
                logger.info(f"æ¶ˆæ¯ {i}/{len(messages)} (Markdown) å‘é€æˆåŠŸ")
                continue
            else:
                logger.warning(f"æ¶ˆæ¯ {i} Markdown å‘é€å¤±è´¥ ({resp.text})ï¼Œå°è¯•çº¯æ–‡æœ¬é‡å‘...")
        except Exception as e:
            logger.warning(f"æ¶ˆæ¯ {i} ç½‘ç»œå¼‚å¸¸: {e}")

        # æ–¹æ¡ˆ B: é™çº§ä¸ºçº¯æ–‡æœ¬å‘é€
        payload_plain = {
            "chat_id": TELEGRAM_CHAT_ID,
            "text": msg,
            "disable_web_page_preview": True,
        }

        try:
            resp = requests.post(url, json=payload_plain, timeout=30)
            if resp.status_code == 200:
                logger.info(f"æ¶ˆæ¯ {i}/{len(messages)} (çº¯æ–‡æœ¬) å‘é€æˆåŠŸ")
            else:
                logger.error(f"æ¶ˆæ¯ {i} å½»åº•å¤±è´¥: {resp.text}")
                all_success = False
        except Exception as e:
            logger.error(f"æ¶ˆæ¯ {i} çº¯æ–‡æœ¬é‡å‘å¼‚å¸¸: {e}")
            all_success = False

    return all_success


# ============================================================
# ä¸»æµç¨‹
# ============================================================

def main():
    """ä¸»å‡½æ•°ï¼šåè°ƒæ•´ä¸ªå·¥ä½œæµç¨‹"""
    logger.info("=" * 50)
    logger.info("åŒ»ç–—æƒ…æŠ¥æ”¶é›†æœºå™¨äººå¯åŠ¨ (v3.0 å¤šæ¨¡å‹ç‰ˆ)")
    logger.info(f"å½“å‰ AI æä¾›å•†: {AI_PROVIDER.upper()}")
    logger.info("=" * 50)

    # 1. åŠ è½½å†å²è®°å½•
    history = load_history()

    # 2. è·å– RSS æ–‡ç« 
    all_articles = fetch_rss_articles(RSS_SOURCES)

    # 3. è¿‡æ»¤æ–°æ–‡ç« 
    new_articles = filter_new_articles(all_articles, history)

    if not new_articles:
        logger.info("æ²¡æœ‰æ–°æ–‡ç« ï¼Œä»»åŠ¡ç»“æŸ")
        return

    # 4. AI æ€»ç»“
    summary = generate_ai_summary(new_articles)

    # 5. æ¨é€æ¶ˆæ¯
    if summary:
        send_telegram_message(summary)
    else:
        # AI å¤±è´¥æ—¶çš„å¤‡é€‰æ–¹æ¡ˆ
        fallback = f"ğŸ“… {datetime.now().strftime('%Y-%m-%d')} æ–°æ–‡çŒ®é€šçŸ¥ (AI ç”Ÿæˆå¤±è´¥)\n\n"
        fallback += "\n".join([f"â€¢ {a['title']}\n  {a['link']}" for a in new_articles[:5]])
        send_telegram_message(fallback)

    # 6. ä¿å­˜å†å²è®°å½•
    for a in new_articles:
        history.add(a["id"])
    save_history(history)

    logger.info("ä»»åŠ¡å®Œæˆ")


if __name__ == "__main__":
    main()
