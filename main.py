# filename: main.py
"""
åŒ»ç–—æƒ…æŠ¥è‡ªåŠ¨æ”¶é›†ä¸æ¨é€æœºå™¨äºº (v3.0 å¤šæ¨¡å‹ç‰ˆ)
åŠŸèƒ½: ä»RSSæºè·å–åŒ»å­¦æ–‡çŒ®ï¼Œä½¿ç”¨AIæ€»ç»“ï¼Œæ¨é€åˆ°Telegram
æ”¯æŒ: Gemini, DeepSeek, è±†åŒ…(Doubao), é€šä¹‰åƒé—®(Qwen)
"""

import os
import json
import logging
import time
import re
from datetime import datetime
from typing import Optional

import feedparser
import requests
import google.generativeai as genai
from openai import OpenAI

# ============================================================
# é…ç½®åŒºåŸŸ
# ============================================================

# Telegram é…ç½®
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID", "")

# AI æä¾›å•†é€‰æ‹©: gemini, deepseek, doubao, qwen
AI_PROVIDER = os.environ.get("AI_PROVIDER", "gemini").lower()

# å„ AI æä¾›å•†çš„ API Key
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")
DEEPSEEK_API_KEY = os.environ.get("DEEPSEEK_API_KEY", "")
DOUBAO_API_KEY = os.environ.get("DOUBAO_API_KEY", "")
QWEN_API_KEY = os.environ.get("QWEN_API_KEY", "")

# è‡ªå®šä¹‰æ¨¡å‹åç§° (å¯é€‰ï¼Œç”¨äºæŒ‡å®šå…·ä½“æ¨¡å‹æˆ–è±†åŒ…çš„æ¥å…¥ç‚¹ID)
AI_MODEL_NAME = os.environ.get("AI_MODEL_NAME", "")

# RSS æºåˆ—è¡¨
RSS_SOURCES = [
    {
        "name": "PubMed - Pediatric SLE",
        # æœç´¢å…³é”®è¯ï¼šSystemic Lupus Erythematosus AND Child
        "url": "https://pubmed.ncbi.nlm.nih.gov/rss/search/14_xQ7JEOWXDuopaPahtu8vYOV9ttMUxoq8IeKOLBpA7Zak9UG/?limit=15&utm_campaign=pubmed-2&fc=20260103215413",
    },
    {
        "name": "ClinicalTrials - Pediatric Lupus",
        # æœç´¢å…³é”®è¯ï¼šSLE (Condition) + Child (Term)
        "url": "https://clinicaltrials.gov/api/rss?cond=Systemic+Lupus+Erythematosus&term=Child",
    },
    # ============================================================
    # --- 2. é¡¶çº§æœŸåˆŠ (å¢åŠ äº† ?filter=... å‚æ•°) ---
    # é€»è¾‘ï¼šåªæœ‰æ ‡é¢˜æˆ–ç®€ä»‹é‡Œå«æœ‰ Lupus(ç‹¼ç–®) æˆ– SLE çš„æ–‡ç« æ‰ä¼šè¢«æŠ“å–
    {
        "name": "NEJM (æ–°è‹±æ ¼å…°åŒ»å­¦æ‚å¿— - ç‹¼ç–®ç›¸å…³)",
        "url": "https://rsshub.app/nejm/toc/nejm?filter=Lupus|SLE|Systemic%20Lupus",
    },
    {
        "name": "The Lancet (æŸ³å¶åˆ€ - ç‹¼ç–®ç›¸å…³)",
        "url": "https://rsshub.app/lancet/toc/lancet?filter=Lupus|SLE|Systemic%20Lupus",
    },
    {
        "name": "Nature Medicine (ç‹¼ç–®ç›¸å…³)",
        "url": "https://rsshub.app/nature/journal/nm?filter=Lupus|SLE|Systemic%20Lupus",
    },

    # --- 3. é£æ¹¿å…ç–«é¡¶åˆŠ (èŒƒå›´ç¨å¾®æ”¾å®½) ---
    {
        "name": "Annals of the Rheumatic Diseases (ARD)",
        # ARD æœ¬èº«å°±æ˜¯é£æ¹¿åˆŠï¼Œæˆ‘ä»¬å¯ä»¥ä¸è¿‡æ»¤(çœ‹å…¨ç§‘åŠ¨æ€)ï¼Œæˆ–è€…ä¹Ÿåªçœ‹ç‹¼ç–®
        # ä¸‹é¢æ¼”ç¤ºçš„æ˜¯åªçœ‹ç‹¼ç–® (å¦‚æƒ³çœ‹æ‰€æœ‰é£æ¹¿åŠ¨æ€ï¼ŒæŠŠ ?filter... åˆ æ‰å³å¯)
        "url": "https://rsshub.app/bmj/journals/ard?filter=Lupus|SLE|Systemic%20Lupus|Autoimmune",
    }
]

# å†å²è®°å½•æ–‡ä»¶è·¯å¾„
HISTORY_FILE = "history.json"

# æœ€å¤§å†å²è®°å½•æ•°é‡ï¼ˆé˜²æ­¢æ–‡ä»¶æ— é™å¢å¤§ï¼‰
MAX_HISTORY_SIZE = 1000

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)

# ============================================================
# å†å²è®°å½•ç®¡ç†
# ============================================================

def load_history() -> set:
    """åŠ è½½å†å²è®°å½•æ–‡ä»¶"""
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                logger.info(f"å·²åŠ è½½ {len(data)} æ¡å†å²è®°å½•")
                return set(data)
        except (json.JSONDecodeError, IOError) as e:
            logger.warning(f"è¯»å–å†å²è®°å½•å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨ç©ºè®°å½•")
            return set()
    else:
        logger.info("å†å²è®°å½•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°è®°å½•")
        return set()

def save_history(history: set) -> None:
    """ä¿å­˜å†å²è®°å½•åˆ°æ–‡ä»¶"""
    history_list = list(history)
    if len(history_list) > MAX_HISTORY_SIZE:
        history_list = history_list[-MAX_HISTORY_SIZE:]
    
    try:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(history_list, f, ensure_ascii=False, indent=2)
        logger.info(f"å·²ä¿å­˜ {len(history_list)} æ¡å†å²è®°å½•")
    except IOError as e:
        logger.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")

# ============================================================
# RSS è§£æ (å¸¦ Session å’Œ Headers ä¼ªè£…)
# ============================================================

def fetch_rss_articles(sources: list) -> list:
    """ä»RSSæºè·å–æ–‡ç« åˆ—è¡¨ï¼ŒåŒ…å«åçˆ¬è™«ç­–ç•¥"""
    articles = []
    session = requests.Session()

    for source in sources:
        source_name = source.get("name", "Unknown")
        url = source.get("url", "")

        if not url: continue
        logger.info(f"æ­£åœ¨è·å–: {source_name}")

        # é’ˆå¯¹ä¸åŒæ¥æºå®šåˆ¶ Headers
        if "pubmed" in url.lower():
            headers = {
                'User-Agent': 'MedicalIntelligenceBot/1.0 (Research Purpose)',
                'Referer': 'https://pubmed.ncbi.nlm.nih.gov/',
                'Accept': '*/*'
            }
        else:
            # ClinicalTrials ç­‰å…¶ä»–ç½‘ç«™æ¨¡æ‹Ÿæµè§ˆå™¨
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            }

        try:
            # å»¶æ—¶é¿å…å°ç¦
            time.sleep(2)
            response = session.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            
            feed = feedparser.parse(response.content)
            
            current_count = 0
            for entry in feed.entries:
                article_id = entry.get("id") or entry.get("link") or entry.get("title", "")
                if not article_id: continue

                articles.append({
                    "id": article_id,
                    "title": entry.get("title", "æ— æ ‡é¢˜"),
                    "link": entry.get("link", ""),
                    "summary": entry.get("summary", entry.get("description", "æ— æ‘˜è¦")),
                    "source": source_name,
                    "published": entry.get("published", ""),
                })
                current_count += 1
            
            logger.info(f"ä» '{source_name}' è·å–äº† {current_count} ç¯‡æ–‡ç« ")

        except Exception as e:
            logger.error(f"è·å– '{source_name}' å¤±è´¥: {e}")

    session.close()
    return articles

def filter_new_articles(articles: list, history: set) -> list:
    """è¿‡æ»¤æ–°æ–‡ç« """
    new_articles = [a for a in articles if a.get("id") and a.get("id") not in history]
    logger.info(f"å‘ç° {len(new_articles)} ç¯‡æ–°æ–‡ç« ")
    return new_articles

# ============================================================
# AI æ€»ç»“ (å¤šæ¨¡å‹æ”¯æŒ)
# ============================================================

def build_prompt(articles: list) -> str:
    """æ„å»ºå‘é€ç»™ AI çš„ Prompt"""
    articles_text = ""
    for i, article in enumerate(articles, 1):
        articles_text += f"\n--- æ–‡ç«  {i} ---\næ ‡é¢˜: {article['title']}\næ‘˜è¦: {article['summary'][:500]}...\né“¾æ¥: {article['link']}\n"

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªé£æ¹¿å…ç–«ç§‘ä¸“å®¶ï¼Œè¯·å°†ä»¥ä¸‹å…³äº"å„¿ç«¥çº¢æ–‘ç‹¼ç–®"çš„æœ€æ–°æ–‡çŒ®æ•´ç†æˆä¸­æ–‡æ—¥æŠ¥ã€‚

æ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d')}

è¦æ±‚ï¼š
1. åˆ†ä¸ºã€é‡ç£…ã€‘ã€ã€ä¸´åºŠã€‘ã€ã€åŸºç¡€ã€‘ä¸‰ç±»ã€‚
2. æ¯ä¸ªæ¡ç›®åŒ…å«ï¼šä¸­æ–‡æ ‡é¢˜ã€ä¸€å¥è¯é€šä¿—è§£è¯»ã€åŸæ–‡é“¾æ¥ã€‚
3. ä¿æŒä¸“ä¸šä¸”æ˜“è¯»ã€‚
4. é‡è¦ï¼šè¯·ä¸è¦åœ¨è¾“å‡ºä¸­ä½¿ç”¨ä¸é—­åˆçš„ Markdown ç¬¦å·ï¼ˆå¦‚å•ä¸ª * æˆ– _ï¼‰ï¼Œå°½é‡é¿å…ä½¿ç”¨å¤æ‚çš„æ ¼å¼ï¼Œä½¿ç”¨çº¯æ–‡æœ¬æˆ–ç®€å•çš„ emoji å³å¯ã€‚

å¾…å¤„ç†æ–‡çŒ®ï¼š
{articles_text}
"""
    return prompt


def generate_with_gemini(prompt: str) -> Optional[str]:
    """ä½¿ç”¨ Google Gemini ç”Ÿæˆæ€»ç»“"""
    if not GEMINI_API_KEY:
        logger.error("æœªé…ç½® GEMINI_API_KEY")
        return None

    try:
        genai.configure(api_key=GEMINI_API_KEY)
        
        logger.info("æ­£åœ¨è‡ªåŠ¨é€‰æ‹©æœ€ä½³ Gemini æ¨¡å‹...")
        available_models = []
        try:
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    available_models.append(m.name)
        except Exception as e:
            logger.warning(f"æ— æ³•åˆ—å‡ºæ¨¡å‹ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤å€¼: {e}")

        # é»˜è®¤å›é€€æ¨¡å‹
        model_name = AI_MODEL_NAME if AI_MODEL_NAME else "models/gemini-pro"
        
        # ä¼˜å…ˆé€‰æ‹©ç­–ç•¥ï¼šFlash > Pro > å…¶ä»–
        if available_models and not AI_MODEL_NAME:
            flash_models = [m for m in available_models if 'flash' in m]
            pro_models = [m for m in available_models if 'pro' in m]
            
            if flash_models:
                model_name = flash_models[0]
            elif pro_models:
                model_name = pro_models[0]
        
        logger.info(f"å·²é€‰æ‹© Gemini æ¨¡å‹: {model_name}")
        model = genai.GenerativeModel(model_name)
        
        response = model.generate_content(prompt)
        if response and response.text:
            logger.info("Gemini æ€»ç»“ç”ŸæˆæˆåŠŸ")
            return response.text
            
    except Exception as e:
        logger.error(f"Gemini æ€»ç»“å¤±è´¥: {e}")
    
    return None


def generate_with_openai_compatible(prompt: str, provider: str) -> Optional[str]:
    """
    ä½¿ç”¨ OpenAI å…¼å®¹æ¨¡å¼è°ƒç”¨ DeepSeek / è±†åŒ… / é€šä¹‰åƒé—®
    
    Args:
        prompt: è¦å‘é€çš„æç¤ºè¯
        provider: æä¾›å•†åç§° (deepseek, doubao, qwen)
    
    Returns:
        ç”Ÿæˆçš„æ–‡æœ¬ï¼Œå¤±è´¥è¿”å› None
    """
    # æ ¹æ®æä¾›å•†é…ç½® base_url, api_key, default_model
    config = {
        "deepseek": {
            "base_url": "https://api.deepseek.com",
            "api_key": DEEPSEEK_API_KEY,
            "default_model": "deepseek-chat",
        },
        "doubao": {
            "base_url": "https://ark.cn-beijing.volces.com/api/v3",
            "api_key": DOUBAO_API_KEY,
            "default_model": "",  # è±†åŒ…å¿…é¡»é€šè¿‡ AI_MODEL_NAME æŒ‡å®šæ¥å…¥ç‚¹ID
        },
        "qwen": {
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "api_key": QWEN_API_KEY,
            "default_model": "qwen-plus",
        },
    }
    
    if provider not in config:
        logger.error(f"æœªçŸ¥çš„ AI æä¾›å•†: {provider}")
        return None
    
    cfg = config[provider]
    api_key = cfg["api_key"]
    base_url = cfg["base_url"]
    model_name = AI_MODEL_NAME if AI_MODEL_NAME else cfg["default_model"]
    
    if not api_key:
        logger.error(f"æœªé…ç½® {provider.upper()}_API_KEY")
        return None
    
    if not model_name:
        logger.error(f"ä½¿ç”¨ {provider} æ—¶å¿…é¡»é€šè¿‡ AI_MODEL_NAME ç¯å¢ƒå˜é‡æŒ‡å®šæ¨¡å‹/æ¥å…¥ç‚¹ID")
        return None
    
    logger.info(f"æ­£åœ¨è°ƒç”¨ {provider.upper()} API (æ¨¡å‹: {model_name})...")
    
    try:
        client = OpenAI(
            api_key=api_key,
            base_url=base_url,
        )
        
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é£æ¹¿å…ç–«ç§‘åŒ»å­¦æ–‡çŒ®åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=4096,
        )
        
        if response and response.choices and response.choices[0].message:
            result = response.choices[0].message.content
            logger.info(f"{provider.upper()} æ€»ç»“ç”ŸæˆæˆåŠŸ")
            return result
            
    except Exception as e:
        logger.error(f"{provider.upper()} æ€»ç»“å¤±è´¥: {e}")
    
    return None


def generate_ai_summary(articles: list) -> Optional[str]:
    """
    æ ¹æ® AI_PROVIDER é…ç½®è°ƒç”¨å¯¹åº”çš„ AI æœåŠ¡ç”Ÿæˆæ€»ç»“
    
    æ”¯æŒçš„æä¾›å•†:
    - gemini: Google Gemini (é»˜è®¤)
    - deepseek: DeepSeek
    - doubao: å­—èŠ‚è·³åŠ¨è±†åŒ…
    - qwen: é˜¿é‡Œé€šä¹‰åƒé—®
    """
    if not articles:
        logger.info("æ²¡æœ‰æ–°æ–‡ç« ï¼Œæ— éœ€AIæ€»ç»“")
        return None
    
    prompt = build_prompt(articles)
    
    logger.info(f"å½“å‰ AI æä¾›å•†: {AI_PROVIDER.upper()}")
    
    if AI_PROVIDER == "gemini":
        return generate_with_gemini(prompt)
    elif AI_PROVIDER in ["deepseek", "doubao", "qwen"]:
        return generate_with_openai_compatible(prompt, AI_PROVIDER)
    else:
        logger.error(f"ä¸æ”¯æŒçš„ AI æä¾›å•†: {AI_PROVIDER}ï¼Œæ”¯æŒçš„å€¼: gemini, deepseek, doubao, qwen")
        return None

# ============================================================
# Telegram æ¨é€ (é˜²æŠ¥é”™å¢å¼ºç‰ˆ)
# ============================================================

def escape_markdown(text: str) -> str:
    """
    è½¬ä¹‰ Telegram Markdown ä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œé˜²æ­¢è§£æé”™è¯¯
    ä¸»è¦å¤„ç†ä¸æˆå¯¹çš„ * _ ` [ ç­‰ç¬¦å·
    """
    # ç®€å•ç­–ç•¥ï¼šå°†å¯èƒ½å¯¼è‡´é—®é¢˜çš„å•ä¸ªç‰¹æ®Šå­—ç¬¦è½¬ä¹‰
    # ä½†ä¿ç•™ emoji å’ŒåŸºæœ¬æ ¼å¼
    
    # æ£€æµ‹å¹¶ä¿®å¤ä¸æˆå¯¹çš„ * å’Œ _
    def fix_unpaired(text: str, char: str) -> str:
        count = text.count(char)
        if count % 2 != 0:
            # å¥‡æ•°ä¸ªï¼Œè¯´æ˜æœ‰ä¸æˆå¯¹çš„ï¼Œå…¨éƒ¨è½¬ä¹‰
            text = text.replace(char, '\\' + char)
        return text
    
    text = fix_unpaired(text, '*')
    text = fix_unpaired(text, '_')
    text = fix_unpaired(text, '`')
    
    # è½¬ä¹‰ [ ä½†ä¸è½¬ä¹‰å·²ç»æ­£ç¡®é—­åˆçš„é“¾æ¥æ ¼å¼
    # ç®€å•å¤„ç†ï¼šå¦‚æœ [ åé¢æ²¡æœ‰å¯¹åº”çš„ ]( åˆ™è½¬ä¹‰
    result = []
    i = 0
    while i < len(text):
        if text[i] == '[':
            # æŸ¥æ‰¾æ˜¯å¦æ˜¯æœ‰æ•ˆçš„é“¾æ¥æ ¼å¼ [text](url)
            close_bracket = text.find(']', i)
            if close_bracket != -1 and close_bracket + 1 < len(text) and text[close_bracket + 1] == '(':
                # å¯èƒ½æ˜¯æœ‰æ•ˆé“¾æ¥ï¼Œä¿ç•™
                result.append(text[i])
            else:
                # ä¸æ˜¯æœ‰æ•ˆé“¾æ¥ï¼Œè½¬ä¹‰
                result.append('\\[')
        else:
            result.append(text[i])
        i += 1
    
    return ''.join(result)


def send_telegram_message(text: str) -> bool:
    """å‘é€æ¶ˆæ¯åˆ° Telegramï¼Œå¤±è´¥æ—¶è‡ªåŠ¨é™çº§ä¸ºçº¯æ–‡æœ¬"""
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID: 
        logger.error("æœªé…ç½® TELEGRAM_BOT_TOKEN æˆ– TELEGRAM_CHAT_ID")
        return False

    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    
    # åˆ‡åˆ†é•¿æ¶ˆæ¯
    max_length = 4000
    messages = []
    remaining = text
    while len(remaining) > 0:
        if len(remaining) > max_length:
            # å¯»æ‰¾æœ€è¿‘çš„æ¢è¡Œç¬¦åˆ‡åˆ†
            split_idx = remaining.rfind('\n', 0, max_length)
            if split_idx == -1: split_idx = max_length
            messages.append(remaining[:split_idx])
            remaining = remaining[split_idx:].lstrip('\n')
        else:
            messages.append(remaining)
            remaining = ""

    all_success = True
    for i, msg in enumerate(messages, 1):
        # -------------------------------------------------------
        # æ–¹æ¡ˆ A: å°è¯• Markdown å‘é€ (é¢„å…ˆè½¬ä¹‰ç‰¹æ®Šå­—ç¬¦)
        # -------------------------------------------------------
        escaped_msg = escape_markdown(msg)
        payload = {
            "chat_id": TELEGRAM_CHAT_ID,
            "text": escaped_msg,
            "parse_mode": "Markdown",
            "disable_web_page_preview": True
        }
        
        try:
            resp = requests.post(url, json=payload, timeout=30)
            if resp.status_code == 200:
                logger.info(f"æ¶ˆæ¯ {i}/{len(messages)} (Markdown) å‘é€æˆåŠŸ")
                continue
            else:
                logger.warning(f"æ¶ˆæ¯ {i} Markdown å‘é€å¤±è´¥ ({resp.text})ï¼Œå°è¯•çº¯æ–‡æœ¬é‡å‘...")
        except Exception as e:
            logger.warning(f"æ¶ˆæ¯ {i} ç½‘ç»œå¼‚å¸¸: {e}")

        # -------------------------------------------------------
        # æ–¹æ¡ˆ B: é™çº§ä¸ºçº¯æ–‡æœ¬å‘é€ (ä¿åº•)
        # -------------------------------------------------------
        payload_plain = {
            "chat_id": TELEGRAM_CHAT_ID,
            "text": msg,  # ä½¿ç”¨åŸå§‹æ¶ˆæ¯ï¼Œä¸è½¬ä¹‰
            "disable_web_page_preview": True
        }
        
        try:
            resp = requests.post(url, json=payload_plain, timeout=30)
            if resp.status_code == 200:
                logger.info(f"æ¶ˆæ¯ {i}/{len(messages)} (çº¯æ–‡æœ¬) å‘é€æˆåŠŸ")
            else:
                logger.error(f"æ¶ˆæ¯ {i} å½»åº•å¤±è´¥: {resp.text}")
                all_success = False
        except Exception as e:
            logger.error(f"æ¶ˆæ¯ {i} çº¯æ–‡æœ¬é‡å‘å¼‚å¸¸: {e}")
            all_success = False

    return all_success

# ============================================================
# ä¸»æµç¨‹
# ============================================================

def main():
    logger.info("=" * 50)
    logger.info("åŒ»ç–—æƒ…æŠ¥æ”¶é›†æœºå™¨äººå¯åŠ¨ (v3.0 å¤šæ¨¡å‹ç‰ˆ)")
    logger.info(f"å½“å‰ AI æä¾›å•†: {AI_PROVIDER.upper()}")
    logger.info("=" * 50)

    # 1. åŠ è½½å†å²
    history = load_history()

    # 2. è·å– RSS
    all_articles = fetch_rss_articles(RSS_SOURCES)
    
    # 3. è¿‡æ»¤æ–°æ–‡ç« 
    new_articles = filter_new_articles(all_articles, history)

    if not new_articles:
        logger.info("æ²¡æœ‰æ–°æ–‡ç« ï¼Œä»»åŠ¡ç»“æŸ")
        return

    # 4. AI æ€»ç»“
    summary = generate_ai_summary(new_articles)

    # 5. æ¨é€æ¶ˆæ¯
    if summary:
        send_telegram_message(summary)
    else:
        # AI å¤±è´¥æ—¶çš„å¤‡é€‰æ–¹æ¡ˆ
        fallback = f"ğŸ“… {datetime.now().strftime('%Y-%m-%d')} æ–°æ–‡çŒ®é€šçŸ¥ (AIç”Ÿæˆå¤±è´¥)\n\n"
        fallback += "\n".join([f"â€¢ {a['title']}\n  {a['link']}" for a in new_articles[:5]])
        send_telegram_message(fallback)

    # 6. ä¿å­˜å†å² (æ ‡è®°ä¸ºå·²è¯»)
    for a in new_articles:
        history.add(a["id"])
    save_history(history)

    logger.info("ä»»åŠ¡å®Œæˆ")

if __name__ == "__main__":
    main()
